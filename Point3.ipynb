{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import heapq\n",
    "from scipy.spatial import distance\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "from heapq import heappush\n",
    "N_doc=26543\n",
    "\n",
    "#from script_module import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-z]+') #Change this line by removing 0-9 if we don't want numbers in the plot tokens.\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index_1.pkl', 'rb') as handle:\n",
    "    inverted_index = pickle.load(handle)\n",
    "with open('vocabulary.pkl', 'rb') as handle:\n",
    "    vocabulary = pickle.load(handle)\n",
    "with open('vocabulary2.pkl', 'rb') as handle:\n",
    "    vocabulary2 = pickle.load(handle)\n",
    "with open('tfIdf_index.pkl', 'rb') as handle:\n",
    "    tfIdf_index = pickle.load(handle)\n",
    "with open('BookTokens.pkl', 'rb') as handle:\n",
    "    BookTokens = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bookTitle():\n",
    "    def name():\n",
    "        return \"bookTitle\"\n",
    "    def parse(soup):\n",
    "        bookTitle = soup.find_all('h1')[0].contents[0]\n",
    "        bookTitle = \" \".join(bookTitle.split())\n",
    "        return (bookTitle)\n",
    "    def score(book_info,query):\n",
    "        w1 = set(book_info)\n",
    "        w2 = set(query)\n",
    "\n",
    "        return 1-nltk.jaccard_distance(w1, w2)\n",
    "\n",
    "class bookSeries():\n",
    "    def name():\n",
    "        return \"bookSeries\"\n",
    "    def parse(soup):\n",
    "        bookSeries=\"\"\n",
    "        bookSeries=soup.find('h2',id=\"bookSeries\").text.strip()[1:-1]\n",
    "        return bookSeries\n",
    "    def score(book_info,query):\n",
    "        w1 = set(book_info)\n",
    "        w2 = set(query)\n",
    "\n",
    "        return 1-nltk.jaccard_distance(w1, w2)\n",
    "\n",
    "class bookAuthors():\n",
    "    def name():\n",
    "        return \"bookAuthors\"\n",
    "    def parse(soup):\n",
    "        bookAuthors=[]\n",
    "        for element in soup.find_all(\"span\",itemprop=\"name\"):\n",
    "            bookAuthors.append(element.text.strip())\n",
    "        return print_list(bookAuthors)\n",
    "    def score(book_info,query):\n",
    "        w1=book_info.lower()\n",
    "        w1=w1.split(\";\")\n",
    "\n",
    "        w2 = query.lower()\n",
    "        w2 = w2.split(\",\")\n",
    "        score=[]\n",
    "\n",
    "\n",
    "        for word_query in w1:\n",
    "            temp_score=0\n",
    "            for element in w2:\n",
    "                temp_score=max(1-nltk.jaccard_distance(set(word_query.strip()), set(element.strip())),temp_score)\n",
    "            score.append(temp_score)\n",
    "\n",
    "        return sum(score)/len(score)\n",
    "\n",
    "class ratingValue():\n",
    "    def name():\n",
    "        return \"ratingValue\"\n",
    "    def parse(soup):\n",
    "        ratingValue = soup.find_all('span',itemprop=\"ratingValue\")[0].contents[0].split('\\n')[1].strip() \n",
    "        return ratingValue\n",
    "    def score(book_info,query):\n",
    "        \n",
    "        def custom_tanh(x,parameter):\n",
    "            value=3/2*(x-parameter+2)\n",
    "            return((np.tanh(value))+1)/2\n",
    "        \n",
    "        try:\n",
    "            query=float(query)\n",
    "        except ValueError:\n",
    "            print (\"Warning; failed conversion of\",query,\"to float\")\n",
    "            return 0\n",
    "        \n",
    "        if query<0 or query>5:\n",
    "            print(\"Warning: value ouside of the range 0-5\")\n",
    "            \n",
    "        return custom_tanh(float(book_info),query)\n",
    "\n",
    "class ratingCount():\n",
    "    def name():\n",
    "        return \"ratingCount\"  \n",
    "    def parse(soup):\n",
    "        return str(soup.find(\"meta\",itemprop=\"ratingCount\").get(\"content\"))\n",
    "    def score(book_info,query):\n",
    "        try:\n",
    "            book_info=int(book_info)\n",
    "            query=int(query)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "        \n",
    "        return min(1,book_info/query)\n",
    "        \n",
    "class reviewCount():\n",
    "    def name():\n",
    "        return \"reviewCount\"\n",
    "    def parse(soup):\n",
    "        return str(soup.find(\"meta\",itemprop=\"reviewCount\").get(\"content\"))\n",
    "    def score(book_info,query):\n",
    "        try:\n",
    "            book_info=int(book_info)\n",
    "            query=int(query)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "        \n",
    "        return min(1,book_info/query)\n",
    "\n",
    "class Plot():\n",
    "    def name():\n",
    "        return \"Plot\"\n",
    "    def parse(soup):\n",
    "        def headingToRemove(Plot): \n",
    "            to_check=Plot.find(\"i\")\n",
    "            if to_check:\n",
    "                forbidden_strings=[\"isbn\",\"edition\",\"librarian's note\"]\n",
    "                for string in forbidden_strings:\n",
    "                    if string in to_check.text.lower():\n",
    "                        Plot.find(\"i\").decompose()\n",
    "\n",
    "        Plot=soup.find(\"div\", id=\"descriptionContainer\").find_all(\"span\")\n",
    "\n",
    "        if len(Plot)==2:\n",
    "            Plot=Plot[1]\n",
    "            headingToRemove(Plot)\n",
    "            Plot=Plot.text\n",
    "            Plot=\" \".join(Plot.split())\n",
    "            Plot=Plot.replace(\"\\\\\",\"\")\n",
    "        elif len(Plot)==1: \n",
    "            Plot=Plot[0]\n",
    "            headingToRemove(Plot)\n",
    "            Plot=Plot.text\n",
    "            Plot=\" \".join(Plot.split())\n",
    "            Plot=Plot.replace(\"\\\\\",\"\")\n",
    "        else:\n",
    "            Plot=\"\"\n",
    "        return Plot\n",
    "    def score(book_info,query):\n",
    "        pass\n",
    "\n",
    "\n",
    "class NumberOfPages():\n",
    "    def name():\n",
    "        return \"NumberOfPages\"\n",
    "    def parse(soup):\n",
    "        N_pages=soup.find_all('span', itemprop=\"numberOfPages\")\n",
    "        if N_pages:\n",
    "            return N_pages[0].contents[0].replace('\\n', '').strip().split()[0]\n",
    "        return \"\"\n",
    "    def score(book_info,query):\n",
    "        \n",
    "        try:\n",
    "            n_pages=int(book_info)\n",
    "        except (ValueError,TypeError) as e:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            query=int(query)\n",
    "        \n",
    "        except (ValueError,TypeError) as e:\n",
    "            print(\"This should not be printed\")\n",
    "            return 0\n",
    "        \n",
    "        exponent=-(1/60*(n_pages-query))**2\n",
    "        return np.exp(exponent)\n",
    "    \n",
    "class Publishing_Date():\n",
    "    def name():\n",
    "        return \"Publishing_Date\"\n",
    "    def parse(soup):\n",
    "        elements = [e for e in soup.find_all(\"div\", class_=\"row\") if re.match(r'Published',e.text.strip())]\n",
    "        #We first try to get the \"first published date\"\n",
    "        if elements:\n",
    "            date=re.findall(r'(?<=\\(first published )(.*?)(?=\\))',elements[0].text)\n",
    "        else:\n",
    "            return \"\"\n",
    "        if date:\n",
    "            return date[0]\n",
    "        #We now see if there is a publishing date (but not a first publishing one).\n",
    "        date=\" \".join(elements[0].text.split()).split()\n",
    "        #Handling the issue that not always the date is in the same format \n",
    "        if date[1]!=\"by\":\n",
    "            Publishing_Date=date[1]\n",
    "            if len(date)>2 and date[2]!=\"by\":\n",
    "                Publishing_Date+=\" \"+date[2]\n",
    "                if len(date)>3 and date[3]!=\"by\":\n",
    "                    Publishing_Date+=\" \"+date[3]\n",
    "            return Publishing_Date\n",
    "        else:\n",
    "            return \"\"\n",
    "    def score(book_info,query):\n",
    "        if book_info:\n",
    "            get_date=book_info.split(\" \")[-1]\n",
    "        try:\n",
    "            get_date=int(get_date)\n",
    "        except (ValueError,TypeError,UnboundLocalError) as e:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            query=int(query)\n",
    "        \n",
    "        except (ValueError,TypeError) as e:\n",
    "            \n",
    "            print(\"This should not be printed\")\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "        exponent=-((2/(2030-query)**0.8)*(get_date-query))**2\n",
    "        return np.exp(exponent)\n",
    "\n",
    "        \n",
    "class Characters():\n",
    "    def name ():\n",
    "        return \"Characters\"\n",
    "    def parse(soup):\n",
    "        Characters=soup.find_all(\"a\",{'href': re.compile(r'^/characters/')})\n",
    "        characters=[]\n",
    "        for item in Characters:\n",
    "            characters.append(\" \".join(item.text.split()))\n",
    "        return print_list(characters)\n",
    "    def score(book_info,query):\n",
    "        w1=book_info.lower()\n",
    "        w1=w1.split(\";\")\n",
    "\n",
    "        w2 = query.lower()\n",
    "        w2 = w2.split(\",\")\n",
    "        score=[]\n",
    "\n",
    "\n",
    "        for word_query in w1:\n",
    "            temp_score=0\n",
    "            for element in w2:\n",
    "                temp_score=max(1-nltk.jaccard_distance(set(word_query.strip()), set(element.strip())),temp_score)\n",
    "            score.append(temp_score)\n",
    "\n",
    "        return sum(score)/len(score)\n",
    "\n",
    "class Setting():\n",
    "    def name():\n",
    "        return \"Setting\"\n",
    "    def parse(soup):\n",
    "        Setting_temp=soup.find_all(\"div\",class_=\"infoBoxRowItem\")\n",
    "        Setting=[]\n",
    "        temp=[]\n",
    "        Setting_places = []\n",
    "        for element in Setting_temp:\n",
    "            if element.find(\"a\",{'href': re.compile(r'^/places/')}):\n",
    "                Setting_places=element\n",
    "        if Setting_places:\n",
    "            temp=Setting_places.find_all()\n",
    "        else:\n",
    "            Setting=[]\n",
    "        for element in temp:\n",
    "            if element.name==\"a\":\n",
    "                to_insert=element.text.split()\n",
    "                Setting.append(\" \".join(to_insert))\n",
    "            if element.name==\"span\":\n",
    "                to_add=element.text.split()\n",
    "                Setting[-1]+=\" \"+(\" \".join(to_add))\n",
    "        #This is only a vert long workaround but seems to work\n",
    "        for i in range(len(Setting)):\n",
    "            Setting[i]=Setting[i].replace(\"…more\",\"\").replace(\"…less\",\"\").strip()\n",
    "        Setting=list(dict.fromkeys([x for x in Setting if x]))\n",
    "        return print_list(Setting)\n",
    "    def score(book_info,query):\n",
    "        \n",
    "        w1=book_info.lower()\n",
    "        w1=w1.split(\";\")\n",
    "\n",
    "        w2 = query.lower()\n",
    "        w2 = w2.split(\",\")\n",
    "        score=[]\n",
    "\n",
    "\n",
    "        for word_query in w1:\n",
    "            temp_score=0\n",
    "            for element in w2:\n",
    "                temp_score=max(1-nltk.jaccard_distance(set(word_query.strip()), set(element.strip())),temp_score)\n",
    "            score.append(temp_score)\n",
    "\n",
    "        return sum(score)/len(score)\n",
    "\n",
    "\n",
    "class Url():\n",
    "    def name():\n",
    "        return \"Url\"\n",
    "    def parse(soup):\n",
    "        return re.findall(r'(?<=link href=\")(.*?)(?=\")',str(soup))[0]\n",
    "    def score(book_info,query):\n",
    "        print(\"Warning: a score for Url is not implemented. Returning default value of 1\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfIdfScore_plot(query):\n",
    "    query = tokenizer.tokenize(query.lower())\n",
    "    query_stems = [stemmer.stem(word) for word in query if word not in stop_words]\n",
    "\n",
    "    query_stem_test=query_stems\n",
    "    query_stems=[]\n",
    "\n",
    "    #Checking if input stems exists in the vocabulary\n",
    "\n",
    "    for word in query_stem_test:\n",
    "        try:\n",
    "            vocabulary[word]\n",
    "            query_stems.append(word)\n",
    "        except KeyError:\n",
    "            print(\"Stem\",word,\"not found. It will be ignored.\")\n",
    "\n",
    "    query_stems=list(dict.fromkeys([x for x in query_stems])) #Removing possible similarities\n",
    "\n",
    "    ##########################\n",
    "    temp=set()\n",
    "\n",
    "    if len(query_stems)>0:\n",
    "        temp=inverted_index[vocabulary[query_stems[0]]]\n",
    "        for stem in query_stems:\n",
    "            temp=temp.intersection(inverted_index[vocabulary[stem]])\n",
    "\n",
    "    matching_books=list(sorted(temp))\n",
    "\n",
    "    #Calculating tfIdf for the query.\n",
    "    query_tfIdf=[]\n",
    "\n",
    "    for word in query_stems:\n",
    "        query_tfIdf.append((vocabulary[word],np.log(N_doc/vocabulary2[vocabulary[word]])))\n",
    "    query_tfIdf.sort()\n",
    "\n",
    "    query_tfIdf=dict((x,y) for x,y in query_tfIdf)\n",
    "\n",
    "\n",
    "\n",
    "    BooksWithScore=[]\n",
    "    \n",
    "    for book in matching_books:\n",
    "        doc_vector=[]\n",
    "        query_vector=[]\n",
    "        for word_id in BookTokens[book]:\n",
    "            doc_vector.append(word_id[1])\n",
    "            if word_id[0] in query_tfIdf:\n",
    "                query_vector.append(1)\n",
    "            else:\n",
    "                query_vector.append(0)\n",
    "\n",
    "        doc_vector=np.array(doc_vector)\n",
    "        query_vector=np.array(query_vector)\n",
    "        cos_similarity=1-distance.cosine(doc_vector,query_vector)\n",
    "\n",
    "        heappush(BooksWithScore, (book,cos_similarity))\n",
    "    \n",
    "    BooksWithScore.sort(key=lambda x: -x[1])\n",
    "    return BooksWithScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=[bookTitle,bookSeries,bookAuthors,ratingValue,ratingCount,reviewCount,NumberOfPages,Publishing_Date,Characters,Setting,Url]\n",
    "\n",
    "def SearchEngine3(fields_list):\n",
    "    print(\"Write the plot keywords\")\n",
    "    plot_input=input()\n",
    "    print()\n",
    "    print(\"Write other parameters, specifing the field separated by a ','. Example: numberofpages 235, title hunger\")\n",
    "    text_input=input()\n",
    "    text_input=text_input.split(\",\")\n",
    "    field_names=[x.name().lower() for x in fields]  \n",
    "    query_dictionary={}\n",
    "    for input_field in text_input:\n",
    "        input_field=input_field.split()\n",
    "        if input_field and input_field[0].lower() in field_names:\n",
    "            if input_field[0] in query_dictionary:\n",
    "                print(\"Warning: field\",input_field[0],\"inserted more than once. Only the first value will be used\")\n",
    "                continue\n",
    "\n",
    "            if len(input_field)>1:\n",
    "                query_dictionary[input_field[0]]=\" \".join(input_field[1:len(input_field)])\n",
    "            else:\n",
    "                print(\"Warning: the field\",input_field[0],\"has no specified value\")\n",
    "        else:\n",
    "            if input_field:\n",
    "                print(\"Warning: the field\",'\"'+input_field[0]+'\"', \"does not exist!\")\n",
    "            else:\n",
    "                print(\"Warning: empty field name entered\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(query_dictionary)\n",
    "    \n",
    "    to_call=[]\n",
    "    for element in query_dictionary:\n",
    "        to_call.append(field_names.index(element))\n",
    "    \n",
    "    Book_with_plot_score=(TfIdfScore_plot(plot_input))\n",
    "    Book_with_plot_normalized=[]\n",
    "    #We decided to normalize the plot TfIdf score so that the best match has 1 as a score to give more importance to it.\n",
    "    if Book_with_plot_score:\n",
    "        max_value=Book_with_plot_score[0][1]\n",
    "        for book in Book_with_plot_score:\n",
    "            Book_with_plot_normalized.append((book[0],book[1]/max_value))\n",
    "    \n",
    "    Book_with_plot_score=Book_with_plot_normalized\n",
    "\n",
    "    \n",
    "    Book_with_full_score=[] #initializing the heap structure\n",
    "    \n",
    "    for element in Book_with_plot_score:\n",
    "        book=element[0]\n",
    "        plot_score=element[1]\n",
    "        temp_score=0\n",
    "        with open('articles/article_' + str(book) +'.tsv', 'r', encoding=\"utf-8\") as file:\n",
    "            temp = csv.DictReader(file, delimiter = '\\t')\n",
    "            for row in temp:\n",
    "                for field in query_dictionary:\n",
    "                    field_name=fields_list[field_names.index(field)].name()\n",
    "                    temp_score+=fields_list[field_names.index(field)].score(row[field_name],query_dictionary[field])\n",
    "        score=temp_score+plot_score\n",
    "        \n",
    "        heappush(Book_with_full_score, (score,book))\n",
    "   \n",
    "                    \n",
    "    top_k_books=heapq.nlargest(10,Book_with_full_score)\n",
    "    \n",
    "    for book in top_k_books:\n",
    "        i=book[1]\n",
    "        with open('articles/article_' + str(i) +'.tsv', 'r', encoding=\"utf-8\") as file:\n",
    "            temp = csv.DictReader(file, delimiter = '\\t')\n",
    "            for row in temp:\n",
    "                print(\"BookTitle:\",row[\"bookTitle\"])\n",
    "                print(\"Plot:\")\n",
    "                print(row[\"Plot\"])\n",
    "                print(\"Url:\",row[\"Url\"])\n",
    "                print(\"Score:\",book[0])\n",
    "                print()\n",
    "\n",
    "\n",
    "                    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the plot keywords\n",
      "love\n",
      "\n",
      "Write other parameters, specifing the field separated by a ','. Example: numberofpages 235, title hunger\n",
      "booktitle love, bookseries love, ratingcount 1000\n",
      "{'booktitle': 'love', 'bookseries': 'love', 'ratingcount': '1000'}\n",
      "BookTitle: All About Love: New Visions\n",
      "Plot:\n",
      "All About Love offers radical new ways to think about love by showing its interconnectedness in our private and public lives. In eleven concise chapters, hooks explains how our everyday notions of what it means to give and receive love often fail us, and how these ideals are established in early childhood. She offers a rethinking of self-love (without narcissism) that will bring peace and compassion to our personal and professional lives, and asserts the place of love to end struggles between individuals, in communities, and among societies. Moving from the cultural to the intimate, hooks notes the ties between love and loss and challenges the prevailing notion that romantic love is the most important love of all. Visionary and original, hooks shows how love heals the wounds we bear as individuals and as a nation, for it is the cornerstone of compassion and forgiveness and holds the power to overcome shame. For readers who have found ongoing delight and wisdom in bell hooks's life and work, and for those who are just now discovering her, All About Love is essential reading and a brilliant book that will change how we think about love, our culture-and one another.\n",
      "Url: https://www.goodreads.com/book/show/17607.All_About_Love\n",
      "Score: 2.032027450719\n",
      "\n",
      "BookTitle: Fallen in Love\n",
      "Plot:\n",
      "And in a twist of fate, four extraordinary love stories intersect over the course of a romantic Valentine’s Day in medieval England. Miles and Shelby find love where they least expect it. Roland learns a painful lesson about finding and losing love. Arriane pays the price for a love so fierce it burns. And for the first—and last—time, Daniel and Luce spend a night together like none other. Lauren Kate’s FALLEN IN LOVE is filled with love stories… the ones everyone has been waiting for.\n",
      "Url: https://www.goodreads.com/book/show/12588363-fallen-in-love\n",
      "Score: 1.9543055389504334\n",
      "\n",
      "BookTitle: Revelation\n",
      "Plot:\n",
      "In the dark world of protectors, futures are fated, love destroys, and sacrifices are certain. From bestselling author Randi Cooley Wilson comes a darkly romantic twist to an epic paranormal romance story about a divine secret, a loyal protector, and a forbidden love. Eighteen-year-old Eve Collins started college unaware that one revelation would challenge everything she’s believed to be true about her family, life, and future. Around every corner, danger, secrets, and lies quickly become her new reality. And holding all the answers is the very attractive Asher St. Michael. Dark and mysterious, Asher is appointed to protect Eve at all costs. Bound by his oath of loyalty to mankind, he is forbidden from loving her. Drawn to one another by their forbidden attraction, they descend into a world filled with treachery, deceit, and darkness. A world where they find themselves caught in the middle of a centuries-old war. A world where they are forced to decide what they will sacrifice for love. Revelation is a journey of self-discovery, love, and sacrifice. It is the first full-length book within the Revelation Series, which is meant to be read in release order. Intended for mature readers.\n",
      "Url: https://www.goodreads.com/book/show/20787232-revelation\n",
      "Score: 1.929149563967581\n",
      "\n",
      "BookTitle: Pyar Ka Pehla Shehr / پیار کا پہلا شہر\n",
      "Plot:\n",
      "A Love Story.\n",
      "Url: https://www.goodreads.com/book/show/2684609-pyar-ka-pehla-shehr\n",
      "Score: 1.8762380952380953\n",
      "\n",
      "BookTitle: Forever\n",
      "Plot:\n",
      "then. When Sam met Grace, he was a wolf and she was a girl. Eventually he found a way to become a boy, and their love moved from curious distance to the intense closeness of shared lives. now. That should have been the end of their story. But Grace was not meant to stay human. Now she is the wolf. And the wolves of Mercy Falls are about to be killed in one final, spectacular hunt. forever. Sam would do anything for Grace. But can one boy and one love really change a hostile, predatory world? The past, the present, and the future are about to collide in one pure moment--a moment of death or life, farewell or forever.\n",
      "Url: https://www.goodreads.com/book/show/9409458-forever\n",
      "Score: 1.8426000611584405\n",
      "\n",
      "BookTitle: Loved\n",
      "Plot:\n",
      "A book to rival TWILIGHT and VAMPIRE DIARIES, and one that will have you wanting to keep reading until the very last page! If you are into adventure, love and vampires this book is the one for you! --Vampirebooksite.com (Turned) LOVED is Book #2 in the #1 Bestselling series THE VAMPIRE JOURNALS, which begins with Book #1, TURNED! In LOVED (Book #2 in the Vampire Journals), Caitlin and Caleb embark together on their quest to find the one object that can stop the imminent vampire and human war: the lost sword. An object of vampire lore, there is grave doubt over whether it even exists. If there is any hope of finding it, they must first trace Caitlin’s ancestry. Is she really the One? Their search begins with finding Caitlin’s father. Who was he? Why did he abandon her? As the search broadens, they are shocked by what they discover about who she really is. But they are not the only ones searching for the legendary sword. The Blacktide Coven wants it, too, and they are close on Caitlin and Caleb’s trail. Worse, Caitlin’s little brother, Sam, remains obsessed with finding his Dad. But Sam soon finds himself in way over his head, smack in the middle of a vampire war. Will he jeopardize their search? Caitlin and Caleb’s journey takes them on a whirlwind of historic locations—from the Hudson Valley, to Salem, to the heart of historic Boston—the very spot where witches were once hung on the hill of Boston Common. Why are these locations so important to the vampire race? And what do they have to do with Caitlin’s ancestry, and with who she’s becoming? But they may not even make it. Caitlin and Caleb’s love for each other is blossoming. And their forbidden romance may just destroy everything they’ve set out to achieve…. “LOVED, the second book in the Vampire Journals series, is just as great as the first book, TURNED, and jam packed with action, romance, adventure, and suspense. If you loved the first book, get your hands on this one and fall in love all over again.” --Vampirebooksite.com “THE VAMPIRE JOURNALS series has had a great plot, and LOVED especially was the kind of book you will have trouble putting down at night. The ending was a cliffhanger that was so spectacular that you will immediately want to buy the next book, just to see what happens. As you can see, this book was a huge step up in the series and receives a solid A.” --The Dallas Examiner\n",
      "Url: https://www.goodreads.com/book/show/10706481-loved\n",
      "Score: 1.8155216321992735\n",
      "\n",
      "BookTitle: Forever You\n",
      "Plot:\n",
      "New York Times bestselling novel, Forever You is the highly demanded sequel to USA Today’s Bestseller, Forever Black. Connor Black’s life consisted of his company and his use of multiple women. There was never going to be love, relationships, or a fairy-tale life. Emotionally dead and damaged, that stemmed from a personal tragedy, Connor Black vowed never to feel any emotion or fall in love with a woman. That was true until Ellery Lane walked into his life by accident and changed his life forever. He begins experiencing feelings and emotions that he never felt before and finds himself being drawn into her world. You took the journey with Connor and Ellery as their love, courage, and strength were put to the test. You watched their worlds come together through her eyes in Forever Black, and now it's time to take the journey through his in Forever You.\n",
      "Url: https://www.goodreads.com/book/show/17404452-forever-you\n",
      "Score: 1.802938733133365\n",
      "\n",
      "BookTitle: The 5 Love Languages: The Secret to Love that Lasts\n",
      "Plot:\n",
      "Simple ideas, lasting love Falling in love is easy. Staying in love—that’s the challenge! How can you keep your relationship fresh and growing amid the demands, conflicts, and just plain boredom of everyday life? In the #1 New York Times bestseller The 5 Love Languages , you’ll discover the secret that has transformed millions of relationships worldwide. Whether your relationship is flourishing or failing, Dr. Gary Chapman’s proven approach to showing and receiving love will help you experience deeper and richer levels of intimacy with your partner—starting today. The 5 Love Languages is as practical as it is insightful. Updated to reflect the complexities of relationships today, this new edition reveals intrinsic truths and applies relevant, actionable wisdom in ways that work. Includes the Couple's Personal Profile assessment so you can discover your love language and that of your loved one.\n",
      "Url: https://www.goodreads.com/book/show/23878688-the-5-love-languages\n",
      "Score: 1.7991530194903818\n",
      "\n",
      "BookTitle: The Art of Loving\n",
      "Plot:\n",
      "The fiftieth Anniversary Edition of the groundbreaking international bestseller that has shown millions of readers how to achieve rich, productive lives by developing their hidden capacities for love Most people are unable to love on the only level that truly matters: love that is compounded of maturity, self-knowledge, and courage. As with every art, love demands practice and concentration, as well as genuine insight and understanding. In his classic work, The Art of Loving , renowned psychoanalyst and social philosopher Erich Fromm explores love in all its aspects—not only romantic love, steeped in false conceptions and lofty expectations, but also brotherly love, erotic love, self-love, the love of God, and the love of parents for their children.\n",
      "Url: https://www.goodreads.com/book/show/14142.The_Art_of_Loving\n",
      "Score: 1.7871454972049485\n",
      "\n",
      "BookTitle: Effortless\n",
      "Plot:\n",
      "After being caught in the middle of a love triangle that led to a devastating betrayal, Kiera pledged to learn from the mistakes she made. She was determined to never again inflict that kind of pain on anyone, especially the soulful, talented man who held her heart. But life offers new challenges for every relationship, and when Kiera's love is put to the ultimate test, will it survive? Love is easy ... trust is hard.\n",
      "Url: https://www.goodreads.com/book/show/15842441-effortless\n",
      "Score: 1.7808079951352074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SearchEngine3(fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
