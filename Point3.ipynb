{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import heapq\n",
    "from scipy.spatial import distance\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "from heapq import heappush\n",
    "N_doc=26543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-z]+') #Change this line by removing 0-9 if we don't want numbers in the plot tokens.\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index_1.pkl', 'rb') as handle:\n",
    "    inverted_index = pickle.load(handle)\n",
    "with open('vocabulary.pkl', 'rb') as handle:\n",
    "    vocabulary = pickle.load(handle)\n",
    "with open('vocabulary2.pkl', 'rb') as handle:\n",
    "    vocabulary2 = pickle.load(handle)\n",
    "with open('tfIdf_index.pkl', 'rb') as handle:\n",
    "    tfIdf_index = pickle.load(handle)\n",
    "with open('BookTokens.pkl', 'rb') as handle:\n",
    "    BookTokens = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bookTitle():\n",
    "    def name():\n",
    "        return \"bookTitle\"\n",
    "    def parse(soup):\n",
    "        bookTitle = soup.find_all('h1')[0].contents[0]\n",
    "        bookTitle = \" \".join(bookTitle.split())\n",
    "        return (bookTitle)\n",
    "    def score():\n",
    "        pass\n",
    "\n",
    "class bookSeries():\n",
    "    def name():\n",
    "        return \"bookSeries\"\n",
    "    def parse(soup):\n",
    "        bookSeries=\"\"\n",
    "        bookSeries=soup.find('h2',id=\"bookSeries\").text.strip()[1:-1]\n",
    "        return bookSeries\n",
    "\n",
    "class bookAuthors():\n",
    "    def name():\n",
    "        return \"bookAuthors\"\n",
    "    def parse(soup):\n",
    "        bookAuthors=[]\n",
    "        for element in soup.find_all(\"span\",itemprop=\"name\"):\n",
    "            bookAuthors.append(element.text.strip())\n",
    "        return print_list(bookAuthors)\n",
    "\n",
    "class ratingValue():\n",
    "    def name():\n",
    "        return \"ratingValue\"\n",
    "    def parse(soup):\n",
    "        ratingValue = soup.find_all('span',itemprop=\"ratingValue\")[0].contents[0].split('\\n')[1].strip() \n",
    "        return ratingValue\n",
    "\n",
    "class ratingCount():\n",
    "    def name():\n",
    "        return \"ratingCount\"  \n",
    "    def parse(soup):\n",
    "        return str(soup.find(\"meta\",itemprop=\"ratingCount\").get(\"content\"))\n",
    "\n",
    "class reviewCount():\n",
    "    def name():\n",
    "        return \"reviewCount\"\n",
    "    def parse(soup):\n",
    "        return str(soup.find(\"meta\",itemprop=\"reviewCount\").get(\"content\"))\n",
    "\n",
    "\n",
    "class Plot():\n",
    "    def name():\n",
    "        return \"Plot\"\n",
    "    def parse(soup):\n",
    "        def headingToRemove(Plot): \n",
    "            to_check=Plot.find(\"i\")\n",
    "            if to_check:\n",
    "                forbidden_strings=[\"isbn\",\"edition\",\"librarian's note\"]\n",
    "                for string in forbidden_strings:\n",
    "                    if string in to_check.text.lower():\n",
    "                        Plot.find(\"i\").decompose()\n",
    "\n",
    "        Plot=soup.find(\"div\", id=\"descriptionContainer\").find_all(\"span\")\n",
    "\n",
    "        if len(Plot)==2:\n",
    "            Plot=Plot[1]\n",
    "            headingToRemove(Plot)\n",
    "            Plot=Plot.text\n",
    "            Plot=\" \".join(Plot.split())\n",
    "            Plot=Plot.replace(\"\\\\\",\"\")\n",
    "        elif len(Plot)==1: \n",
    "            Plot=Plot[0]\n",
    "            headingToRemove(Plot)\n",
    "            Plot=Plot.text\n",
    "            Plot=\" \".join(Plot.split())\n",
    "            Plot=Plot.replace(\"\\\\\",\"\")\n",
    "        else:\n",
    "            Plot=\"\"\n",
    "        return Plot\n",
    "\n",
    "\n",
    "class NumberOfPages():\n",
    "    def name():\n",
    "        return \"NumberOfPages\"\n",
    "    def parse(soup):\n",
    "        N_pages=soup.find_all('span', itemprop=\"numberOfPages\")\n",
    "        if N_pages:\n",
    "            return N_pages[0].contents[0].replace('\\n', '').strip().split()[0]\n",
    "        return \"\"\n",
    "\n",
    "class Publishing_Date():\n",
    "    def name():\n",
    "        return \"Publishing_Date\"\n",
    "    def parse(soup):\n",
    "        elements = [e for e in soup.find_all(\"div\", class_=\"row\") if re.match(r'Published',e.text.strip())]\n",
    "        #We first try to get the \"first published date\"\n",
    "        if elements:\n",
    "            date=re.findall(r'(?<=\\(first published )(.*?)(?=\\))',elements[0].text)\n",
    "        else:\n",
    "            return \"\"\n",
    "        if date:\n",
    "            return date[0]\n",
    "        #We now see if there is a publishing date (but not a first publishing one).\n",
    "        date=\" \".join(elements[0].text.split()).split()\n",
    "        #Handling the issue that not always the date is in the same format \n",
    "        if date[1]!=\"by\":\n",
    "            Publishing_Date=date[1]\n",
    "            if len(date)>2 and date[2]!=\"by\":\n",
    "                Publishing_Date+=\" \"+date[2]\n",
    "                if len(date)>3 and date[3]!=\"by\":\n",
    "                    Publishing_Date+=\" \"+date[3]\n",
    "            return Publishing_Date\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "        \n",
    "class Characters():\n",
    "    def name ():\n",
    "        return \"Characters\"\n",
    "    def parse(soup):\n",
    "        Characters=soup.find_all(\"a\",{'href': re.compile(r'^/characters/')})\n",
    "        characters=[]\n",
    "        for item in Characters:\n",
    "            characters.append(\" \".join(item.text.split()))\n",
    "        return print_list(characters)\n",
    "\n",
    "class Setting():\n",
    "    def name():\n",
    "        return \"Setting\"\n",
    "    def parse(soup):\n",
    "        Setting_temp=soup.find_all(\"div\",class_=\"infoBoxRowItem\")\n",
    "        Setting=[]\n",
    "        temp=[]\n",
    "        Setting_places = []\n",
    "        for element in Setting_temp:\n",
    "            if element.find(\"a\",{'href': re.compile(r'^/places/')}):\n",
    "                Setting_places=element\n",
    "        if Setting_places:\n",
    "            temp=Setting_places.find_all()\n",
    "        else:\n",
    "            Setting=[]\n",
    "        for element in temp:\n",
    "            if element.name==\"a\":\n",
    "                to_insert=element.text.split()\n",
    "                Setting.append(\" \".join(to_insert))\n",
    "            if element.name==\"span\":\n",
    "                to_add=element.text.split()\n",
    "                Setting[-1]+=\" \"+(\" \".join(to_add))\n",
    "        #This is only a vert long workaround but seems to work\n",
    "        for i in range(len(Setting)):\n",
    "            Setting[i]=Setting[i].replace(\"…more\",\"\").replace(\"…less\",\"\").strip()\n",
    "        Setting=list(dict.fromkeys([x for x in Setting if x]))\n",
    "        return print_list(Setting)\n",
    "\n",
    "\n",
    "class Url():\n",
    "    def name():\n",
    "        return \"Url\"\n",
    "    def parse(soup):\n",
    "        return re.findall(r'(?<=link href=\")(.*?)(?=\")',str(soup))[0]\n",
    "    def score(book,query):\n",
    "        print(\"Warning: a score for Url is not implemented. Returning default value of 1\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=[bookTitle,bookSeries,bookAuthors,ratingValue,ratingCount,reviewCount,NumberOfPages,Publishing_Date,Characters,Setting,Url]\n",
    "\n",
    "def SearchEngine3(fields_list):\n",
    "    print(\"Write the plot keywords\")\n",
    "    plot_input=input()\n",
    "    print(\"Write other parameters, specifing the field separated by a ','. Example: numpages 235, title hunger\")\n",
    "    text_input=input()\n",
    "    text_input=text_input.split(\",\")\n",
    "    field_names=[x.name().lower() for x in fields]  \n",
    "    dictionary={}\n",
    "    for input_field in text_input:\n",
    "        input_field=input_field.split()\n",
    "        if input_field and input_field[0].lower() in field_names:\n",
    "            if input_field[0] in dictionary:\n",
    "                print(\"Warning: field\",input_field[0],\"inserted more than once. Only the first value will be used\")\n",
    "                continue\n",
    "\n",
    "            if len(input_field)>1:\n",
    "                dictionary[input_field[0]]=\" \".join(input_field[1:len(input_field)])\n",
    "            else:\n",
    "                print(\"Warning: the field\",input_field[0],\"has no specified value\")\n",
    "        else:\n",
    "            if input_field:\n",
    "                print(\"Warning: the field\",'\"'+input_field[0]+'\"', \"does not exist!\")\n",
    "            else:\n",
    "                print(\"Warning: empty field name entered\")\n",
    "    \n",
    "    \n",
    "    #testato fino a sopra qua.\n",
    "    \n",
    "    to_call=[]\n",
    "    for element in dictionary:\n",
    "        to_call.append(field_names.index(element))\n",
    "\n",
    "    with open(book):\n",
    "        for index in to_call:\n",
    "\n",
    "            fields_list[index].score(dictionary[fields_list[index].name().lower()],row[fields_list[index].name()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the plot keywords\n",
      "asdads\n",
      "Write other parameters, specifing the field separated by a ','. Example: numpages 235, title hunger\n",
      "booktitle the hunger games, numberofpages 123\n",
      "0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "SearchEngine3(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreNumPages(book,parameter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
