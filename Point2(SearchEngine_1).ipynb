{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "N_doc=26543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-z]+') #Change this line by removing 0-9 if we don't want numbers in the plot tokens.\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer= PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the code used to create these pkl files look at the \"DataStructures\" notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index_1.pkl', 'rb') as handle:\n",
    "    inverted_index = pickle.load(handle)\n",
    "with open('vocabulary.pkl', 'rb') as handle:\n",
    "    vocabulary = pickle.load(handle)\n",
    "with open('tfIdf_index.pkl', 'rb') as handle:\n",
    "    tfIdf_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input()\n",
    "query = tokenizer.tokenize(query.lower())\n",
    "query_stems = [stemmer.stem(word) for word in query if word not in stop_words]\n",
    "\n",
    "query_stem_test=query_stems\n",
    "query_stems=[]\n",
    "\n",
    "#Checking if input stems exists in the vocabulary\n",
    "\n",
    "for word in query_stem_test:\n",
    "    try:\n",
    "        vocabulary[word]\n",
    "        query_stems.append(word)\n",
    "    except KeyError:\n",
    "        print(\"Stem\",word,\"not found. It will be ignored.\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "temp=set()\n",
    "if len(query_stems)>0:\n",
    "    temp=inverted_index[vocabulary[query_stems[0]]]\n",
    "    for stem in query_stems:\n",
    "        temp=temp.intersection(inverted_index[vocabulary[stem]])\n",
    "\n",
    "matching_books=list(sorted(temp))\n",
    "\n",
    "for i in matching_books:\n",
    "    with open('articles/article_' + str(i) +'.tsv', 'r', encoding=\"utf-8\") as file:\n",
    "            temp = csv.DictReader(file, delimiter = '\\t')\n",
    "            for row in temp:\n",
    "                print(\"BookTitle:\",row[\"bookTitle\"])\n",
    "                print(\"Plot:\")\n",
    "                print(row[\"Plot\"])\n",
    "                print(\"Url:\",row[\"Url\"])\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query and ranking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monkey circus\n",
      "[1 1]\n",
      "[0.4178349  0.10445872]\n",
      "\n",
      "[1 1]\n",
      "[0.18723887 0.18723887]\n",
      "\n",
      "[1 1]\n",
      "[0.08114205 0.08114205]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "query = tokenizer.tokenize(query.lower())\n",
    "query_stems = [stemmer.stem(word) for word in query if word not in stop_words]\n",
    "\n",
    "query_stem_test=query_stems\n",
    "query_stems=[]\n",
    "\n",
    "#Checking if input stems exists in the vocabulary\n",
    "\n",
    "for word in query_stem_test:\n",
    "    try:\n",
    "        vocabulary[word]\n",
    "        query_stems.append(word)\n",
    "    except KeyError:\n",
    "        print(\"Stem\",word,\"not found. It will be ignored.\")\n",
    "\n",
    "query_stems=list(dict.fromkeys([x for x in query_stems])) #Removing possible similarities\n",
    "\n",
    "temp=set()\n",
    "\n",
    "if len(query_stems)>0:\n",
    "    temp=inverted_index[vocabulary[query_stems[0]]]\n",
    "    for stem in query_stems:\n",
    "        temp=temp.intersection(inverted_index[vocabulary[stem]])\n",
    "\n",
    "matching_books=list(sorted(temp))\n",
    "\n",
    "books_with_score=[]\n",
    "for book in matching_books:\n",
    "    A=np.array([1]*len(query_stems))\n",
    "    B=[]\n",
    "    for word in query_stems:\n",
    "        tf_Idf_score=dict((x,y) for x,y in tfIdf_index[vocabulary[word]])[book] \n",
    "        B.append(tf_Idf_score)\n",
    "    B=np.array(B)\n",
    "    \n",
    "    print(A)\n",
    "    print(B)\n",
    "    print()\n",
    "    cosine_similarity=1-distance.cosine(A,B)\n",
    "    \n",
    "    #DA CAMBIARE IN UN HEAP\n",
    "    books_with_score.append((book,cosine_similarity))\n",
    "    #DA CAMBIARE IN UN HEAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(162, 0.15671571289882158),\n",
       " (1153, 0.15671571289882158),\n",
       " (1708, 0.27123926165324164),\n",
       " (1821, 0.12894330808130888),\n",
       " (2013, 0.13059642741568464),\n",
       " (2592, 0.13538810734313095),\n",
       " (2763, 0.3183287918257313),\n",
       " (2886, 0.4178348988393238),\n",
       " (3137, 0.07835785644941079),\n",
       " (3483, 0.1872388718575215),\n",
       " (3756, 0.07123441495400981),\n",
       " (3828, 0.11984142751086355),\n",
       " (3875, 0.4157763811601388),\n",
       " (3909, 0.3606650400534226),\n",
       " (4364, 0.15822290263105762),\n",
       " (5169, 0.09889826542158642),\n",
       " (5454, 0.14347213152709018),\n",
       " (6007, 0.19589464112352697),\n",
       " (6178, 0.2838782895904358),\n",
       " (6747, 0.043907419562169835),\n",
       " (6943, 0.2484517399615464),\n",
       " (7430, 0.09431964202243891),\n",
       " (8012, 0.3651297753024407),\n",
       " (8505, 0.14147946303365835),\n",
       " (9012, 0.18256488765122034),\n",
       " (9236, 0.35007339493797285),\n",
       " (9492, 0.049660705189919635),\n",
       " (9837, 0.033451469345310895),\n",
       " (9851, 0.08630340143512233),\n",
       " (10458, 0.118447922539807),\n",
       " (11187, 0.06929606352668981),\n",
       " (11541, 0.06791014225615602),\n",
       " (12047, 0.11575592430026593),\n",
       " (12377, 0.08114204508710082),\n",
       " (12689, 0.08168650881894575),\n",
       " (13565, 0.10115203422187943),\n",
       " (13931, 0.14147946303365835),\n",
       " (14044, 0.08020882943640474),\n",
       " (16362, 0.22144611605268266),\n",
       " (16571, 0.14347213152709018),\n",
       " (17360, 0.16699215308890825),\n",
       " (17530, 0.13954138819758086),\n",
       " (17616, 0.004779967493681401),\n",
       " (17900, 0.15623855550404206),\n",
       " (18019, 0.08669379862488003),\n",
       " (18193, 0.15434123240035458),\n",
       " (18840, 0.07154656079108547),\n",
       " (19181, 0.042316564223271444),\n",
       " (19395, 0.11193979492772971),\n",
       " (20290, 0.008830967783635372),\n",
       " (20556, 0.03319361593658551),\n",
       " (20674, 0.07299940967990144),\n",
       " (21063, 0.18450026086143623),\n",
       " (21388, 0.07594699326290766),\n",
       " (22292, 0.032578248948055194),\n",
       " (22819, 0.17624086514659926),\n",
       " (23035, 0.051888966432222926),\n",
       " (24221, 0.1455217334060486),\n",
       " (24842, 0.06929606352668981),\n",
       " (24991, 0.2263671408538534),\n",
       " (26085, 0.14605191012097626),\n",
       " (26480, 0.21637878689893553),\n",
       " (26534, 0.15671571289882158)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdf_index[vocabulary[\"monkey\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict((x,y) for x,y in tfIdf_index[vocabulary[\"circu\"]])[book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2886, 0.8574929257125441), (3483, 1.0), (12377, 1.0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-2a3435c6cc25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "1-distance.cosine(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_stems=list(dict.fromkeys([x for x in query_stems]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2886, 3483, 12377]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surviv', 'forest']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 0.22742123784892376)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdf_index[vocabulary[\"circu\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56, 0.22742123784892376),\n",
       " (211, 0.26868040069424876),\n",
       " (1078, 0.06977069409879043),\n",
       " (1618, 0.16699215308890825),\n",
       " (1775, 0.2078881905800694),\n",
       " (2118, 0.10950730481367901),\n",
       " (2236, 0.07512382674508404),\n",
       " (2593, 0.13561963082662082),\n",
       " (2886, 0.10445872470983095),\n",
       " (3483, 0.1872388718575215),\n",
       " (4112, 0.02960230960832343),\n",
       " (4422, 0.39178928224705395),\n",
       " (4439, 0.07032129005824783),\n",
       " (4521, 0.21635072404513975),\n",
       " (5991, 0.08477350801536943),\n",
       " (6107, 0.14980178438857944),\n",
       " (6703, 0.07223910475769542),\n",
       " (6875, 0.11575592430026593),\n",
       " (7421, 0.19130928211529372),\n",
       " (8095, 0.11082815914335724),\n",
       " (9024, 0.1785499725174995),\n",
       " (9717, 0.20637769908398818),\n",
       " (10896, 0.118447922539807),\n",
       " (11449, 0.5076822958211055),\n",
       " (11844, 0.05447337614130161),\n",
       " (12377, 0.08114204508710082),\n",
       " (12443, 0.027004021806196113),\n",
       " (13465, 0.18863928404487781),\n",
       " (13694, 0.22894805097805493),\n",
       " (13789, 0.08401216068905713),\n",
       " (13898, 0.9530092695543669),\n",
       " (14043, 0.1131835704269267),\n",
       " (14103, 0.08488767782019502),\n",
       " (14684, 0.03783960730559814),\n",
       " (15163, 0.0681042247055214),\n",
       " (16035, 0.37727856808975563),\n",
       " (16612, 0.47831100261869963),\n",
       " (16916, 0.46302369720106373),\n",
       " (17087, 0.3453058080821492),\n",
       " (17164, 0.04448262593197992),\n",
       " (17792, 0.01490911467461963),\n",
       " (17994, 0.25466303346058505),\n",
       " (18437, 0.06063405558585358),\n",
       " (18814, 0.15845004769650006),\n",
       " (19055, 0.058965056881139476),\n",
       " (19186, 0.39178928224705395),\n",
       " (19673, 0.09609925790965473),\n",
       " (20274, 0.13582028451231204),\n",
       " (21313, 0.18256488765122034),\n",
       " (21491, 0.09889826542158642),\n",
       " (22011, 0.11262664896928708),\n",
       " (22293, 0.07197564649628092),\n",
       " (22858, 0.16577933192334973),\n",
       " (23326, 0.13827857020484258),\n",
       " (23673, 0.11445529593734159),\n",
       " (24360, 0.25466303346058505),\n",
       " (25479, 0.08418612676382978),\n",
       " (25692, 0.32593433249272263),\n",
       " (25776, 0.14147946303365835),\n",
       " (25936, 0.047831100261869965),\n",
       " (26192, 0.18863928404487781),\n",
       " (26423, 0.5361327020222842),\n",
       " (26453, 0.06172619021467167),\n",
       " (26500, 0.2910434668120972)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdf_index[vocabulary[\"circu\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
