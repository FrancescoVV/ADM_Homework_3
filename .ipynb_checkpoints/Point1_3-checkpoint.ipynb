{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(l):\n",
    "    lenght=len(l)\n",
    "    if lenght==0:\n",
    "        return \"\"\n",
    "    if lenght==1:\n",
    "        return l[0]\n",
    "    to_print=\"\"\n",
    "    if lenght>1:\n",
    "        for i in range(lenght-1):\n",
    "            to_print+=l[i]+\", \"\n",
    "        to_print+=l[lenght-1]\n",
    "    return to_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bookTitle():\n",
    "    def name():\n",
    "        return \"bookTitle\"\n",
    "    def parse(soup):\n",
    "        bookTitle = soup.find_all('h1')[0].contents[0]\n",
    "        bookTitle = \" \".join(bookTitle.split())\n",
    "        return (bookTitle)\n",
    "\n",
    "class bookSeries():\n",
    "    def name():\n",
    "        return \"bookSeries\"\n",
    "    def parse(soup):\n",
    "        bookSeries=\"\"\n",
    "        bookSeries=soup.find('h2',id=\"bookSeries\").text.strip()[1:-1]\n",
    "        return bookSeries\n",
    "\n",
    "class bookAuthors():\n",
    "    def name():\n",
    "        return \"bookAuthors\"\n",
    "    def parse(soup):\n",
    "        bookAuthors=[]\n",
    "        for element in soup.find_all(\"span\",itemprop=\"name\"):\n",
    "            bookAuthors.append(element.text.strip())\n",
    "        return print_list(bookAuthors)\n",
    "\n",
    "class ratingValue():\n",
    "    def name():\n",
    "        return \"ratingValue\"\n",
    "    def parse(soup):\n",
    "        ratingValue = soup.find_all('span',itemprop=\"ratingValue\")[0].contents[0].split('\\n')[1].strip() \n",
    "        return ratingValue\n",
    "\n",
    "class ratingCount():\n",
    "    def name():\n",
    "        return \"ratingCount\"  \n",
    "    def parse(soup):\n",
    "        return str(soup.find(\"meta\",itemprop=\"ratingCount\").get(\"content\"))\n",
    "\n",
    "class reviewCount():\n",
    "    def name():\n",
    "        return \"reviewCount\"\n",
    "    def parse(soup):\n",
    "        return str(soup.find(\"meta\",itemprop=\"reviewCount\").get(\"content\"))\n",
    "\n",
    "\n",
    "class Plot():\n",
    "    def name():\n",
    "        return \"Plot\"\n",
    "    def parse(soup):\n",
    "        def headingToRemove(Plot): \n",
    "            to_check=Plot.find(\"i\")\n",
    "            if to_check:\n",
    "                forbidden_strings=[\"isbn\",\"edition\",\"librarian's note\"]\n",
    "                for string in forbidden_strings:\n",
    "                    if string in to_check.text.lower():\n",
    "                        Plot.find(\"i\").decompose()\n",
    "\n",
    "        Plot=soup.find(\"div\", id=\"descriptionContainer\").find_all(\"span\")\n",
    "\n",
    "        if len(Plot)==2:\n",
    "            Plot=Plot[1]\n",
    "            headingToRemove(Plot)\n",
    "            Plot=Plot.text\n",
    "            Plot=\" \".join(Plot.split())\n",
    "            Plot=Plot.replace(\"\\\\\",\"\")\n",
    "        elif len(Plot)==1: \n",
    "            Plot=Plot[0]\n",
    "            headingToRemove(Plot)\n",
    "            Plot=Plot.text\n",
    "            Plot=\" \".join(Plot.split())\n",
    "            Plot=Plot.replace(\"\\\\\",\"\")\n",
    "        else:\n",
    "            Plot=\"\"\n",
    "        return Plot\n",
    "\n",
    "\n",
    "class NumberOfPages():\n",
    "    def name():\n",
    "        return \"NumberOfPages\"\n",
    "    def parse(soup):\n",
    "        N_pages=soup.find_all('span', itemprop=\"numberOfPages\")\n",
    "        if N_pages:\n",
    "            return N_pages[0].contents[0].replace('\\n', '').strip().split()[0]\n",
    "        return \"\"\n",
    "\n",
    "class Publishing_Date():\n",
    "    def name():\n",
    "        return \"Publishing_Date\"\n",
    "    def parse(soup):\n",
    "        elements = [e for e in soup.find_all(\"div\", class_=\"row\") if re.match(r'Published',e.text.strip())]\n",
    "        #We first try to get the \"first published date\"\n",
    "        if elements:\n",
    "            date=re.findall(r'(?<=\\(first published )(.*?)(?=\\))',elements[0].text)\n",
    "        else:\n",
    "            return \"\"\n",
    "        if date:\n",
    "            return date[0]\n",
    "        #We now see if there is a publishing date (but not a first publishing one).\n",
    "        date=\" \".join(elements[0].text.split()).split()\n",
    "        #Handling the issue that not always the date is in the same format \n",
    "        if date[1]!=\"by\":\n",
    "            Publishing_Date=date[1]\n",
    "            if len(date)>2 and date[2]!=\"by\":\n",
    "                Publishing_Date+=\" \"+date[2]\n",
    "                if len(date)>3 and date[3]!=\"by\":\n",
    "                    Publishing_Date+=\" \"+date[3]\n",
    "            return Publishing_Date\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "        \n",
    "class Characters():\n",
    "    def name ():\n",
    "        return \"Characters\"\n",
    "    def parse(soup):\n",
    "        Characters=soup.find_all(\"a\",{'href': re.compile(r'^/characters/')})\n",
    "        characters=[]\n",
    "        for item in Characters:\n",
    "            characters.append(\" \".join(item.text.split()))\n",
    "        return print_list(characters)\n",
    "\n",
    "class Setting():\n",
    "    def name():\n",
    "        return \"Setting\"\n",
    "    def parse(soup):\n",
    "        Setting_temp=soup.find_all(\"div\",class_=\"infoBoxRowItem\")\n",
    "        Setting=[]\n",
    "        temp=[]\n",
    "        Setting_places = []\n",
    "        for element in Setting_temp:\n",
    "            if element.find(\"a\",{'href': re.compile(r'^/places/')}):\n",
    "                Setting_places=element\n",
    "        if Setting_places:\n",
    "            temp=Setting_places.find_all()\n",
    "        else:\n",
    "            Setting=[]\n",
    "        for element in temp:\n",
    "            if element.name==\"a\":\n",
    "                to_insert=element.text.split()\n",
    "                Setting.append(\" \".join(to_insert))\n",
    "            if element.name==\"span\":\n",
    "                to_add=element.text.split()\n",
    "                Setting[-1]+=\" \"+(\" \".join(to_add))\n",
    "        #This is only a vert long workaround but seems to work\n",
    "        for i in range(len(Setting)):\n",
    "            Setting[i]=Setting[i].replace(\"…more\",\"\").replace(\"…less\",\"\").strip()\n",
    "        Setting=list(dict.fromkeys([x for x in Setting if x]))\n",
    "        return print_list(Setting)\n",
    "\n",
    "\n",
    "class Url():\n",
    "    def name():\n",
    "        return \"Url\"\n",
    "    def parse(soup):\n",
    "        return re.findall(r'(?<=link href=\")(.*?)(?=\")',str(soup))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ajiro (Japan), Tokyo (Japan)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST\n",
    "name=\"/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW3/ADM3/\"+str(3)+\"/\"+str(3)+\".html\"\n",
    "with open(name,\"r\",encoding=\"utf-8\") as file:\n",
    "    #name=\"C:\\\\Users\\\\Stefania\\\\ADM_HW3\\\\ADM3\\\\\"+str(3)+\"\\\\\"+str(3)+\".html\"\n",
    "    soup=BeautifulSoup(file,features=\"html.parser\")\n",
    "Setting.parse(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=[bookTitle,bookSeries,bookAuthors,ratingValue,ratingCount,reviewCount,Plot,NumberOfPages,Publishing_Date,\\\n",
    "           Characters,Setting,Url]\n",
    "\n",
    "header = \"\"\n",
    "for fun in functions[:-1]:\n",
    "    header += fun.name()+\"\\t\"\n",
    "header +=functions[-1].name()\n",
    "count = 1 #for the articles\n",
    "\n",
    "for i in range(1,301):\n",
    "    for j in range(1,101):\n",
    "        name=\"/Users/domenicospoto/Desktop/Sapienza/MScDataScience/AlgorithmicMethodsofDataMiningandLaboratory/HW3/ADM3/\"+str(3)+\"/\"+str(3)+\".html\"\n",
    "        #name=\"C:\\\\Users\\\\Stefania\\\\ADM_HW3\\\\ADM3\\\\\"+str(i)+\"\\\\\"+str(j)+\".html\"\n",
    "        try:\n",
    "            with open(name,\"r\",encoding=\"utf-8\") as file:\n",
    "                if os.path.getsize(name)<100000:\n",
    "                    continue\n",
    "                soup=BeautifulSoup(file,features=\"html.parser\")\n",
    "                second_line = \"\"\n",
    "                for fun in functions[:-1]:\n",
    "                    try:\n",
    "                        second_line += fun.parse(soup)+\"\\t\"\n",
    "                    except:\n",
    "                        print(\"Unspecified exception in for function \", fun.name() ,\" for book j\" , j, \"in page i \" , i)\n",
    "                        second_line += \"\" + \"\\t\"\n",
    "                try:\n",
    "                    second_line += functions[-1].parse(soup)  \n",
    "                except:\n",
    "                    print(\"Unspecified exception in for function \", fun.name() ,\" for book j\" , j, \"in page i \" , i) \n",
    "                    second_line += \"\" + \"\\t\"\n",
    "            name=\"C:\\\\Users\\\\Stefania\\\\ADM_HW3\\\\articles\\\\articles_\"+str(count)+\".tsv\"\n",
    "            with open(name,\"w\",encoding=\"utf-8\") as file:\n",
    "                file.write(header)\n",
    "                file.write(\"\\n\")\n",
    "                file.write(second_line)\n",
    "            count +=1\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_detect(string):\n",
    "    try:\n",
    "        return detect(string)\n",
    "    except LangDetectException:\n",
    "        return \"BADLANGUAGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for i in range(1,29226):\n",
    "    with open('articles/articles_' + str(i) +'.tsv', 'r', encoding=\"utf-8\") as file:\n",
    "        temp = csv.DictReader(file, delimiter = '\\t')\n",
    "        for row in temp:\n",
    "            #print('file' + str(i))\n",
    "            if custom_detect(row['Plot']) != 'en':\n",
    "                count.append(i)\n",
    "                os.remove('articles/articles_' + str(i) +'.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26544"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29226 - len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK the number of books before the deleting and after renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for i in range(1, 29226):\n",
    "    try:\n",
    "        os.rename('articles/articles_' + str(i) +'.tsv', 'articles/articles_' + str(counter) +'.tsv')\n",
    "        counter += 1\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26445"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('algotrading': conda)",
   "language": "python",
   "name": "python37464bitalgotradingconda745421058edb4475bcdf684bffb17224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
